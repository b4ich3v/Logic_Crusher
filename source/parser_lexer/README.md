---

### **Обща концепция**

### **Клас `Token`**

Представлява един токен, извлечен от входния текст.

- **Компоненти и методи:**
   -  **Конструктор `__init__`:**
      - `type_`: Стринг, указващ типа/категорията на токена (например `AND`, `OR`, `IDENTIFIER`).
      - `value`: Действителната стойност или лексема, съвпаднала в входния текст (например "`&&`", "`or`", "`A`"). Това е опционално и по подразбиране е `None`.
   - **Представяне `__repr__`:**
      - Предоставя четимо текстово представяне на токена, полезно за отстраняване на грешки и логване.

 ---
 ### **Клас `Lexer`**

 Обработва входния текст и го разбива на последователност от токени въз основа на дефинираните спецификации.

- **Компоненти и методи:**
   -  **Конструктор `__init__`:**
      - `text`: Входният стринг, съдържащ логическия израз, който ще бъде токенизиран.
      - `token_specification`: Списък от кортежи, където всеки кортеж дефинира:
         - **Тип на токена**: Стринг идентификатор за токена (например AND, OR).
         - **Regex модел**: Регулярен израз, който съвпада с токена в входния текст.
         - Спецификациите обхващат различни логически оператори, скоби, константи (`1`, `0`, `true`, `false`), идентификатори (променливи), интервали (`SKIP`) и               всякакви неочаквани символи (`MISMATCH`).
   - **Създаване на Master Regex `self.token_regex`:**
      - Комбинира всички отделни regex модели за токени в единен регулярен израз, използвайки именувани групи.
      - Операторът `|` се използва за обозначаване на алтернация, което означава, че ще се опитва да съвпадне всеки модел в реда, в който са дефинирани.
      - Именувани групи: `?P<TOKEN_TYPE>pattern` позволява на regex двигателя да идентифицира кой тип токен е бил съвпаднат.

### **Процес на Токенизация `tokenize`** 

Итерара през входния текст и генерира списък от `Token` обекти въз основа на дефинираните спецификации за токени.

- **Компоненти:**
   -  **Инициализация:**
      - `tokens = []`: Инициализира празен списък за съхранение на токените.
   - **Итерация през Съвпаденията:**
      - `re.finditer(self.token_regex, self.text)`: Сканира входния текст и връща итератор от обекти за съвпадение `mo` за всяко съвпадение на дефинираните токен           модели.
   -  **Обработка на Всяко Съвпадение:**
      - `kind = mo.lastgroup`: Взема името на последната съвпаднала именувана група, което указва типа на токена.
      - `value = mo.group(kind)`: Извлича действителния подстринг от входа, който е съвпаднал с модела на токена.
   -  **Обработка на Различни Типове Токени::**
      - **Идентификатори и Константи:**
          - `if kind == "IDENTIFIER" or kind == "CONST"`:
          - Създава `Token` с съответния тип и стойност.
      - **Оператори и Скоби:**
          - `elif kind` in ("`NOT`", "`AND`", "`OR`", "`XOR`", "`NAND`", "`NOR`", "`IMP`", "`EQV`", "`LPAREN`", "`RPAREN`"):
          - По същия начин създава `Token` за всеки оператор или скоба.
      - **Интервали `SKIP`:**
          - `elif kind == "SKIP"`:
          - `continue`: Игнорира интервалите и не генерира токен.
      - **Невалидни Символи `MISMATCH`:**
          - `elif kind == "MISMATCH"`:
          - Повдига изключение, указвайки, че е намерен неочакван символ, включително позицията му в текста.
   - **Токен за Край на Файла `EOF`:**
      - `tokens.append(Token("EOF", None))`: Добавя `EOF` (End of File) токен, който обозначава края на входа. Това е полезно за парсерите да знаят кога входът е            напълно обработен.
   - **Връщане на Списъка с Токени:**
      - `return tokens`: Връща пълния списък от токени, генерирани от входния текст.
     
---
### **Клас `Parser`**

Представлява един токен, извлечен от входния текст.

### **Компоненти и Методи:**

1. **Инициализация `__init__`:**
    - **Процес:**
      - Инициализира парсера с даден списък от токени.
    - **Компоненти:** 
      - `tokens`: Списък от токени, генерирани от лексера.
      - `pos`: Текущата позиция в списъка с токени. Започва от `0`.
      - `current_token`: Текущият токен, който се обработва. Инициализира се с първия токен от списъка.
2. **Метод `eat`:**
    - **Цел:** Потвърждава, че текущият токен е от очаквания тип и премества позицията напред.
    - **Процес:**
      - Проверява дали типа на текущия токен съвпада с `token_type`.
      - Ако съвпада:
         - Увеличава позицията `pos` с 1.
         - Обновява `current_token` с токена на новата позиция.
      - Ако не съвпада:
         - Повдига изключение с информация за очаквания и получен тип токен и позицията.
3. **Метод `parse`:**
    - **Цел:** Стартира процеса на парсинг и връща кореновия възел на AST.
    - **Процес:**
      - Извиква метода `expr()`, който започва парсинга според граматиката.
      - Проверява дали след парсинга текущият токен е `EOF` (End of File), което означава, че входът е напълно обработен.
      - Ако не е `EOF`, повдига изключение за неочакван токен.
      - Връща кореновия възел на AST.
4. **Метод `expr`:**
    - **Цел:** Представлява най-високото ниво в граматиката и започва парсинга с най-високия приоритет.
    - **Процес:**
      - Извиква метода `equiv_expr()`, който обработва еквивалентността `EQV`.
5. **Метод `equiv_expr`:**
    - **Цел:**  Обработва оператора за еквивалентност `EQV`, който има най-нисък приоритет след импликацията.
    - **Процес:**
      - Извиква метода imp_expr(), който обработва импликацията (IMP).
      - Докато текущият токен е EQV:
         - Потвърждава и премества токена `EQV`.
         - Създава нов `EqvNode` с текущия `node` и резултата от `imp_expr()`.
         - Обновява `node` с новия `EqvNode`.
      - Връща крайния `node`.
6. **Метод `imp_expr`:**
    - **Цел:**  Обработва оператора за импликация `IMP`.
    - **Процес:**
      - Извиква метода `or_expr()`, който обработва оператора `OR` и `NOR`.
      - Докато текущият токен е `IMP`:
         - Потвърждава и премества токена `IMP`.
         - Създава нов `ImpNode` с текущия `node` и резултата от `or_expr()`.
         - Обновява `node` с новия `ImpNode`.
      - Връща крайния `node`.
7. **Метод `or_expr`:**
    - **Цел:**  Обработва операторите `OR` и `NOR`.
    - **Процес:**
      - Извиква метода `xor_expr()`, който обработва оператора `XOR`.
      - Докато текущият токен е `OR` или `NOR`:
         - Ако е `OR`:
            - Потвърждава и премества токена `OR`.
            - Създава нов `OrNode` с текущия node и резултата от `xor_expr()`.
            - Обновява `node` с новия `OrNode`.
         - Ако е `NOR`:
            - Потвърждава и премества токена `NOR`.
            - Създава нов `NorNode` с текущия `node` и резултата от `xor_expr()`.
            - Обновява `node` с новия `NorNode`.
      - Връща крайния `node`.
8. **Метод `xor_expr`:**
    - **Цел:**  Обработва оператора `XOR`.
    - **Процес:**
      - Извиква метода `and_expr()`, който обработва оператора `AND`.
      - Докато текущият токен е `XOR`:
         - Потвърждава и премества токена `XOR`.
         - Създава нов `XorNode` с текущия `node` и резултата от `and_expr()`.
         - Обновява `node` с новия `XorNode`.
      - Връща крайния `node`.
9. **Метод `and_expr`:**
    - **Цел:**  Обработва оператора `AND`.
    - **Процес:**
      - Извиква метода `nand_expr()`, който обработва оператора `NAND`.
      - Докато текущият токен е `AND`:
         - Потвърждава и премества токена `AND`.
         - Създава нов `AndNode` с текущия `node` и резултата от `nand_expr()`.
         - Обновява `node` с новия `AndNode`.
      - Връща крайния `node`.
10. **Метод `nand_expr`:**
    - **Цел:**  Обработва оператора `NAND`.
    - **Процес:**
      - Извиква метода `factor()`, който обработва най-ниското ниво на граматиката (променливи, константи, унарни операции и скоби).
      - Докато текущият токен е `NAND`:
         - Потвърждава и премества токена `NAND`.
         - Създава нов `NandNode` с текущия `node` и резултата от `factor()`.
         - Обновява `node` с новия `NandNode`.
      - Връща крайния `node`.
11. **Метод `factor`:**
    - **Цел:**  Обработва най-базовите елементи на израза, като променливи, константи, унарни операции `NOT` и групиране чрез скоби.
    - **Процес:**
      - Взема текущия токен.
      - Унарна операция `NOT`:
         - Ако токенът е `NOT`:
            - Потвърждава и премества токена `NOT`.
            - Рекурсивно извиква `factor()` за обработка на следващия елемент.
            - Създава `NotNod`e с резултата от рекурсивното извикване.
            - Връща `NotNode`.
      - Идентификатор (Променлива):
         - Ако токенът е `IDENTIFIER`:
            - Потвърждава и премества токена.
            - Създава `VariableNode` с името на променливата.
            - Връща `VariableNode`.
      - Константа:
         - Ако токенът е `CONST`:
            - Потвърждава и премества токена.
            - Преобразува стойността на константата в булева стойност (`Tru`e за "`1`" или "`true`", `False` за останалите).
            - Създава `ConstNode` с булевата стойност.
            - Връща `ConstNode`.
      - Групиране чрез Скоби:
         - Ако токенът е `LPAREN` (лява скоба):
            - Потвърждава и премества токена `LPAREN`.
            - Извиква `expr()` за обработка на израза вътре в скобите.
            - Потвърждава и премества токена `RPAREN` (дясна скоба).
            - Връща вътрешния `node`.
      - Неочакван Токен:
         - Ако токенът не съвпада с нито една от горните опции:
            - Повдига изключение за неочакван токен с информация за позицията.
          
### **Граматика и Приоритети**        

Парсерът е реализиран въз основа на рекурсивен низходящ парсинг и следва определена граматика за логически изрази. Приоритетите на операторите са организирани от най-висок до най-нисък, което определя реда на тяхната обработка:

1.**`NOT`** 
2.**`NAND`**
3.**`AND`**
4.**`XOR`**
5.**`OR`**, **`NOR`**
6.**`IMP`**
7.**`EQV`** 

Това означава, че например `NOT` има по-висок приоритет от `AND`, а `AND` от `OR`, и т.н. Парсерът обработва изразите според този ред, изграждайки съответните възли в AST.
