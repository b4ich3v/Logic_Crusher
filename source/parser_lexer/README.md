---

### **Обща концепция**

### **Клас `Token`**

Представлява един токен, извлечен от входния текст.

- **Компоненти:**
  -  **Конструктор `__init__`:**
      - `type_`: Стринг, указващ типа/категорията на токена (например `AND`, `OR`, `IDENTIFIER`).
      - `value`: Действителната стойност или лексема, съвпаднала в входния текст (например "`&&`", "`or`", "`A`"). Това е опционално и по подразбиране е `None`.
  - **Представяне `__repr__`:**
      - Предоставя четимо текстово представяне на токена, полезно за отстраняване на грешки и логване.

 ---
 ### **Клас `Lexer`**

 Обработва входния текст и го разбива на последователност от токени въз основа на дефинираните спецификации.

 - **Компоненти:**
  -  **Конструктор `__init__`:**
      - `text`: Входният стринг, съдържащ логическия израз, който ще бъде токенизиран.
      - `token_specification`: Списък от кортежи, където всеки кортеж дефинира:
         - **Тип на токена**: Стринг идентификатор за токена (например AND, OR).
         - **Regex модел**: Регулярен израз, който съвпада с токена в входния текст.
         - Спецификациите обхващат различни логически оператори, скоби, константи (`1`, `0`, `true`, `false`), идентификатори (променливи), интервали (`SKIP`) и               всякакви неочаквани символи (`MISMATCH`).
  - **Създаване на Master Regex `self.token_regex`:**
      - Комбинира всички отделни regex модели за токени в единен регулярен израз, използвайки именувани групи.
      - Операторът `|` се използва за обозначаване на алтернация, което означава, че ще се опитва да съвпадне всеки модел в реда, в който са дефинирани.
      - Именувани групи: `?P<TOKEN_TYPE>pattern` позволява на regex двигателя да идентифицира кой тип токен е бил съвпаднат.

### **Процес на Токенизация `tokenize`** 

Итерара през входния текст и генерира списък от `Token` обекти въз основа на дефинираните спецификации за токени.

- **Компоненти:**
  -  **Инициализация:**
      - `tokens = []`: Инициализира празен списък за съхранение на токените.
  - **Итерация през Съвпаденията:**
      - `re.finditer(self.token_regex, self.text)`: Сканира входния текст и връща итератор от обекти за съвпадение `mo` за всяко съвпадение на дефинираните токен           модели.
  -  **Обработка на Всяко Съвпадение:**
      - `kind = mo.lastgroup`: Взема името на последната съвпаднала именувана група, което указва типа на токена.
      - `value = mo.group(kind)`: Извлича действителния подстринг от входа, който е съвпаднал с модела на токена.
  -  **Обработка на Различни Типове Токени::**
      - **Идентификатори и Константи:**
          - `if kind == "IDENTIFIER" or kind == "CONST"`:
          - Създава `Token` с съответния тип и стойност.
      - **Оператори и Скоби:**
          - `elif kind` in ("`NOT`", "`AND`", "`OR`", "`XOR`", "`NAND`", "`NOR`", "`IMP`", "`EQV`", "`LPAREN`", "`RPAREN`"):
          - По същия начин създава `Token` за всеки оператор или скоба.
      - **Интервали `SKIP`:**
          - `elif kind == "SKIP"`:
          - `continue`: Игнорира интервалите и не генерира токен.
      - **Невалидни Символи `MISMATCH`:**
          - `elif kind == "MISMATCH"`:
          - Повдига изключение, указвайки, че е намерен неочакван символ, включително позицията му в текста.
  - **Токен за Край на Файла `EOF`:**
      - `tokens.append(Token("EOF", None))`: Добавя `EOF` (End of File) токен, който обозначава края на входа. Това е полезно за парсерите да знаят кога входът е            напълно обработен.
  - **Връщане на Списъка с Токени:**
      - `return tokens`: Връща пълния списък от токени, генерирани от входния текст.
     
